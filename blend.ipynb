{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamdavidcole/stylegan3-fun-blend/blob/main/blend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNa9-V2DuPXG"
      },
      "source": [
        "# Network Blending Experiment\n",
        "\n",
        "test github connect"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Drive Connection"
      ],
      "metadata": {
        "id": "zNUlrgLAzMp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU connection\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReFjlT7CvqrF",
        "outputId": "a7e9c6b1-28d5-4952-d344-4a3101300030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-5bc7d272-c87b-e7aa-cf20-1a95c4d78294)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXr8jWKVvq-E",
        "outputId": "2cb0051f-f304-4b17-e3db-989ae9aa17af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install gdown --upgrade\n",
        "\n",
        "if os.path.isdir(\"/content/drive/MyDrive/stylegan3-fun-blend\"):\n",
        "    %cd \"/content/drive/MyDrive/stylegan3-fun-blend\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !git clone https://github.com/adamdavidcole/stylegan3-fun-blend.git\n",
        "    %cd stylegan3-fun-blend\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    # !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/adamdavidcole/stylegan3-fun-blend.git\n",
        "    %cd stylegan3-fun-blend\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMpqnKu7v5og",
        "outputId": "33bb43a4-dfd5-4ae6-c932-5ab492b40024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/content/drive/MyDrive/stylegan3-fun-blend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update all code files in drive repo \n",
        "!git config --global user.name \"test\"\n",
        "!git config --global user.email \"test@test.com\"\n",
        "!git fetch origin\n",
        "!git pull\n",
        "!git stash\n",
        "!git checkout origin/main -- \"*.py\" \n",
        "!git checkout origin/main -- \"*.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2iq2jrmxUAY",
        "outputId": "59b3a38a-d186-4635-dd9e-a8114a3d4a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Saved working directory and index state WIP on main: 59cff72 drive+collab test3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops ninja gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dKoUIUz86ac",
        "outputId": "08e9e2f9-dbe7-4d74-e0d2-38558fc96bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: ninja, einops\n",
            "Successfully installed einops-0.4.1 ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import dnnlib\n",
        "from dnnlib.util import format_time\n",
        "import legacy\n",
        "import PIL.Image\n",
        "\n",
        "from torch_utils import gen_utils\n",
        "\n"
      ],
      "metadata": {
        "id": "58xfSUxE66_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Setup"
      ],
      "metadata": {
        "id": "P5NZDdiT8FNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network_key = \"butterfly\"\n",
        "cfg=\"stylegan3-r\"\n",
        "pretrained_network = \"ffhqu256\"\n",
        "dataset = \"/content/drive/MyDrive/stylegan3/datasets/butterflys_256_2-256x256.zip\"\n",
        "\n",
        "results_outdir = f\"./results/{network_key}\"\n",
        "training_outdir = f\"{results_outdir}/training\"\n",
        "\n",
        "if not os.path.isdir(training_outdir):\n",
        "    !mkdir -p $results_outdir"
      ],
      "metadata": {
        "id": "33igFzDL8Hp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "dsoohbv60UPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=$training_outdir --data=$dataset \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16  --gamma=6.6 --mirror=1 --kimg=50 --snap=1 --tick=1 --img-snap=1 --cbase=16384 \\\n",
        "    --cfg=$cfg --resume=$pretrained_network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oN1Lw-R9GBT",
        "outputId": "4483604a-904d-4504-93e7-c6e3b22e0949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output directory...\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2,\n",
            "      \"freeze_layers\": 0,\n",
            "      \"freeze_embed\": false\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6,\n",
            "    \"blur_init_sigma\": 0,\n",
            "    \"blur_fade_kimg\": 200.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/stylegan3/datasets/butterflys_256_2-256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 10051,\n",
            "    \"xflip\": true,\n",
            "    \"yflip\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 50,\n",
            "  \"resume_kimg\": 0,\n",
            "  \"kimg_per_tick\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"snap_res\": \"4k\",\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256\"\n",
            "}\n",
            "\n",
            "Output directory:    ./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   50 kimg\n",
            "Dataset path:        /content/drive/MyDrive/stylegan3/datasets/butterflys_256_2-256x256.zip\n",
            "Dataset size:        10051 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "Dataset y-flips:     False\n",
            "\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  20102\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               1048576     3081     [16, 1024, 36, 36]   float32 \n",
            "synthesis.L0_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L0_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L1_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L1_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L2_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L2_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L3_52_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L3_52_1024          1049600     169      [16, 1024, 52, 52]   float16 \n",
            "synthesis.L4_52_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L4_52_1024          1049600     157      [16, 1024, 52, 52]   float16 \n",
            "synthesis.L5_84_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L5_84_1024          1049600     169      [16, 1024, 84, 84]   float16 \n",
            "synthesis.L6_84_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L6_84_1024          1049600     157      [16, 1024, 84, 84]   float16 \n",
            "synthesis.L7_148_724.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L7_148_724          742100      169      [16, 724, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   371412      -        [16, 724]            float32 \n",
            "synthesis.L8_148_512          371200      157      [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          185706      157      [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         92928       169      [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         46517       157      [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         23296       25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         16512       25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         15779565    5576     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 50 kimg...\n",
            "\n",
            "/content/drive/MyDrive/stylegan3-fun-blend/training/augment.py:231: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at  ../aten/src/ATen/native/cuda/jit_utils.cpp:860.)\n",
            "  s = torch.exp2(torch.randn([batch_size], device=device) * self.scale_std)\n",
            "tick 0     kimg 0.0      time 45s          sec/tick 17.6    sec/kimg 549.74  maintenance 27.7   cpumem 4.00   gpumem 10.46  reserved 12.97  augment 0.000\n",
            "tick 1     kimg 1.1      time 3m 47s       sec/tick 173.0   sec/kimg 168.97  maintenance 8.4    cpumem 4.36   gpumem 8.91   reserved 12.38  augment 0.004\n",
            "tick 2     kimg 2.1      time 6m 48s       sec/tick 172.9   sec/kimg 168.87  maintenance 8.6    cpumem 4.53   gpumem 8.93   reserved 12.38  augment 0.014\n",
            "tick 3     kimg 3.1      time 9m 50s       sec/tick 172.9   sec/kimg 168.88  maintenance 8.4    cpumem 4.53   gpumem 8.93   reserved 12.38  augment 0.022\n",
            "tick 4     kimg 4.1      time 12m 51s      sec/tick 173.0   sec/kimg 168.91  maintenance 8.4    cpumem 4.53   gpumem 8.93   reserved 12.38  augment 0.029\n",
            "tick 5     kimg 5.2      time 15m 52s      sec/tick 173.0   sec/kimg 168.90  maintenance 8.4    cpumem 4.53   gpumem 8.93   reserved 12.38  augment 0.037\n",
            "tick 6     kimg 6.2      time 18m 54s      sec/tick 173.0   sec/kimg 168.95  maintenance 8.3    cpumem 4.53   gpumem 8.93   reserved 12.38  augment 0.042\n",
            "tick 7     kimg 7.2      time 21m 55s      sec/tick 173.0   sec/kimg 168.94  maintenance 8.3    cpumem 4.53   gpumem 8.94   reserved 12.38  augment 0.050\n",
            "tick 8     kimg 8.2      time 24m 56s      sec/tick 173.0   sec/kimg 168.95  maintenance 8.3    cpumem 4.53   gpumem 8.94   reserved 12.38  augment 0.060\n",
            "tick 9     kimg 9.2      time 27m 57s      sec/tick 173.0   sec/kimg 168.97  maintenance 8.2    cpumem 4.53   gpumem 8.94   reserved 12.39  augment 0.068\n",
            "tick 10    kimg 10.3     time 30m 59s      sec/tick 173.0   sec/kimg 168.97  maintenance 8.3    cpumem 4.53   gpumem 8.95   reserved 12.39  augment 0.078\n",
            "tick 11    kimg 11.3     time 34m 00s      sec/tick 173.0   sec/kimg 168.97  maintenance 8.2    cpumem 4.53   gpumem 8.96   reserved 12.39  augment 0.086\n",
            "tick 12    kimg 12.3     time 37m 01s      sec/tick 173.0   sec/kimg 168.95  maintenance 8.3    cpumem 4.53   gpumem 8.95   reserved 12.39  augment 0.093\n",
            "tick 13    kimg 13.3     time 40m 03s      sec/tick 173.0   sec/kimg 168.97  maintenance 8.3    cpumem 4.53   gpumem 8.94   reserved 12.39  augment 0.099\n",
            "tick 14    kimg 14.4     time 43m 04s      sec/tick 173.0   sec/kimg 168.97  maintenance 8.3    cpumem 4.53   gpumem 9.01   reserved 12.39  augment 0.109\n",
            "tick 15    kimg 15.4     time 46m 05s      sec/tick 173.0   sec/kimg 168.98  maintenance 8.3    cpumem 4.53   gpumem 8.95   reserved 12.39  augment 0.114\n",
            "tick 16    kimg 16.4     time 49m 06s      sec/tick 173.0   sec/kimg 168.99  maintenance 8.2    cpumem 4.53   gpumem 8.97   reserved 12.39  augment 0.119\n",
            "tick 17    kimg 17.4     time 52m 08s      sec/tick 173.0   sec/kimg 168.99  maintenance 8.2    cpumem 4.53   gpumem 9.00   reserved 12.39  augment 0.124\n",
            "tick 18    kimg 18.5     time 55m 09s      sec/tick 173.1   sec/kimg 169.00  maintenance 8.2    cpumem 4.53   gpumem 8.99   reserved 12.39  augment 0.129\n",
            "tick 19    kimg 19.5     time 58m 10s      sec/tick 173.1   sec/kimg 169.00  maintenance 8.1    cpumem 4.53   gpumem 8.99   reserved 12.39  augment 0.134\n",
            "tick 20    kimg 20.5     time 1h 01m 11s   sec/tick 173.0   sec/kimg 168.97  maintenance 8.2    cpumem 4.53   gpumem 8.97   reserved 12.39  augment 0.140\n",
            "tick 21    kimg 21.5     time 1h 04m 13s   sec/tick 173.1   sec/kimg 169.02  maintenance 8.2    cpumem 4.53   gpumem 8.96   reserved 12.39  augment 0.145\n",
            "tick 22    kimg 22.6     time 1h 07m 14s   sec/tick 173.1   sec/kimg 169.06  maintenance 8.2    cpumem 4.53   gpumem 8.99   reserved 12.39  augment 0.150\n",
            "tick 23    kimg 23.6     time 1h 10m 15s   sec/tick 173.1   sec/kimg 169.05  maintenance 8.2    cpumem 4.53   gpumem 8.97   reserved 12.39  augment 0.152\n",
            "tick 24    kimg 24.6     time 1h 13m 17s   sec/tick 173.1   sec/kimg 169.05  maintenance 8.2    cpumem 4.53   gpumem 8.96   reserved 12.39  augment 0.160\n",
            "tick 25    kimg 25.6     time 1h 16m 18s   sec/tick 173.1   sec/kimg 169.02  maintenance 8.2    cpumem 4.53   gpumem 9.00   reserved 12.39  augment 0.165\n",
            "tick 26    kimg 26.7     time 1h 19m 19s   sec/tick 173.1   sec/kimg 169.05  maintenance 8.1    cpumem 4.53   gpumem 9.01   reserved 12.39  augment 0.170\n",
            "tick 27    kimg 27.7     time 1h 22m 20s   sec/tick 173.1   sec/kimg 169.03  maintenance 8.2    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.172\n",
            "tick 28    kimg 28.7     time 1h 25m 21s   sec/tick 173.1   sec/kimg 169.04  maintenance 8.1    cpumem 4.54   gpumem 8.98   reserved 12.39  augment 0.177\n",
            "tick 29    kimg 29.7     time 1h 28m 23s   sec/tick 173.1   sec/kimg 169.04  maintenance 8.1    cpumem 4.54   gpumem 8.96   reserved 12.39  augment 0.184\n",
            "tick 30    kimg 30.8     time 1h 31m 24s   sec/tick 173.1   sec/kimg 169.06  maintenance 8.1    cpumem 4.54   gpumem 8.96   reserved 12.39  augment 0.184\n",
            "tick 31    kimg 31.8     time 1h 34m 25s   sec/tick 173.1   sec/kimg 169.04  maintenance 8.1    cpumem 4.54   gpumem 9.02   reserved 12.39  augment 0.189\n",
            "tick 32    kimg 32.8     time 1h 37m 26s   sec/tick 173.1   sec/kimg 169.05  maintenance 8.1    cpumem 4.54   gpumem 8.97   reserved 12.39  augment 0.192\n",
            "tick 33    kimg 33.8     time 1h 40m 28s   sec/tick 173.1   sec/kimg 169.04  maintenance 8.1    cpumem 4.54   gpumem 8.98   reserved 12.39  augment 0.192\n",
            "tick 34    kimg 34.8     time 1h 43m 29s   sec/tick 173.2   sec/kimg 169.17  maintenance 8.1    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.197\n",
            "tick 35    kimg 35.9     time 1h 46m 30s   sec/tick 173.1   sec/kimg 169.03  maintenance 8.1    cpumem 4.54   gpumem 8.97   reserved 12.39  augment 0.202\n",
            "tick 36    kimg 36.9     time 1h 49m 31s   sec/tick 173.1   sec/kimg 169.01  maintenance 8.1    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.202\n",
            "tick 37    kimg 37.9     time 1h 52m 32s   sec/tick 173.1   sec/kimg 169.00  maintenance 8.0    cpumem 4.54   gpumem 9.02   reserved 12.39  augment 0.197\n",
            "tick 38    kimg 38.9     time 1h 55m 33s   sec/tick 173.1   sec/kimg 169.03  maintenance 8.0    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.200\n",
            "tick 39    kimg 40.0     time 1h 58m 34s   sec/tick 173.1   sec/kimg 169.02  maintenance 8.0    cpumem 4.54   gpumem 8.97   reserved 12.39  augment 0.205\n",
            "tick 40    kimg 41.0     time 2h 01m 35s   sec/tick 173.1   sec/kimg 169.01  maintenance 8.0    cpumem 4.54   gpumem 9.00   reserved 12.39  augment 0.205\n",
            "tick 41    kimg 42.0     time 2h 04m 37s   sec/tick 173.2   sec/kimg 169.17  maintenance 7.9    cpumem 4.54   gpumem 9.01   reserved 12.39  augment 0.205\n",
            "tick 42    kimg 43.0     time 2h 07m 38s   sec/tick 173.2   sec/kimg 169.16  maintenance 7.9    cpumem 4.54   gpumem 9.01   reserved 12.39  augment 0.207\n",
            "tick 43    kimg 44.1     time 2h 10m 39s   sec/tick 173.2   sec/kimg 169.18  maintenance 7.9    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.212\n",
            "tick 44    kimg 45.1     time 2h 13m 40s   sec/tick 173.3   sec/kimg 169.19  maintenance 7.9    cpumem 4.54   gpumem 8.98   reserved 12.39  augment 0.210\n",
            "tick 45    kimg 46.1     time 2h 16m 41s   sec/tick 173.1   sec/kimg 169.00  maintenance 7.9    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.212\n",
            "tick 46    kimg 47.1     time 2h 19m 42s   sec/tick 173.1   sec/kimg 169.04  maintenance 7.9    cpumem 4.54   gpumem 8.98   reserved 12.39  augment 0.215\n",
            "tick 47    kimg 48.2     time 2h 22m 43s   sec/tick 173.1   sec/kimg 169.01  maintenance 7.9    cpumem 4.54   gpumem 9.00   reserved 12.39  augment 0.220\n",
            "tick 48    kimg 49.2     time 2h 25m 44s   sec/tick 173.1   sec/kimg 169.02  maintenance 8.0    cpumem 4.54   gpumem 8.99   reserved 12.39  augment 0.220\n",
            "tick 49    kimg 50.0     time 2h 28m 12s   sec/tick 140.0   sec/kimg 168.24  maintenance 7.8    cpumem 4.54   gpumem 8.97   reserved 12.39  augment 0.225\n",
            "\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection"
      ],
      "metadata": {
        "id": "CHXnE2IO7lkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projection_source_images_outdir = \"projection_source_images\"\n",
        "projection_source_vectors_outdir = \"projection_source_vectors\"\n"
      ],
      "metadata": {
        "id": "YM7U4UlGuIF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload File \n",
        "if not os.path.isdir(projection_source_images_outdir):\n",
        "  !mkdir -p $projection_source_images_outdir\n",
        "\n",
        "def upload_files():\n",
        "  filepaths = []\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    filepath = f\"{projection_source_images_outdir}/{k}\"\n",
        "    open(filepath, 'wb').write(v)\n",
        "    filepaths.append(filepath)\n",
        "  return list(filepaths)\n",
        "\n",
        "uploaded = upload_files();\n",
        "print(uploaded)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "OfZ0Sc3EM97W",
        "outputId": "6c3ebd9f-7551-4901-f09d-7962270b537d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e355e62-0cd9-400e-bfad-0f55a31dc03b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e355e62-0cd9-400e-bfad-0f55a31dc03b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving alan3.jpg to alan3.jpg\n",
            "['projection_source_images/alan3.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project Image\n",
        "# uploaded_file = uploaded[0]\n",
        "uploaded_file=\"/content/drive/MyDrive/stylegan3-fun-blend/projection_source_images/alan3.jpg\"\n",
        "uploaded_file_name = uploaded_file.split('/')[-1].split('.')[0:-1]\n",
        "uploaded_file_name = ''.join(uploaded_file_name)\n",
        "print(uploaded_file)\n",
        "\n",
        "!python projector.py --outdir=$projection_source_vectors_outdir --target=$uploaded_file --project-in-wplus --num-steps=5000 --save-video --stabilize-projection \\\n",
        "       --cfg=stylegan3-r --network=ffhqu256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS78XvhaOzWN",
        "outputId": "8b99cd00-b196-4863-df9c-0ef0b93df19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stylegan3-fun-blend/projection_source_images/alan3.jpg\n",
            "Loading networks from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\"...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Projecting in W+ latent space...\n",
            "Starting from W midpoint using 10000 samples...\n",
            "Completed 0 of 5000\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "Completed 100 of 5000\n",
            "Completed 200 of 5000\n",
            "Completed 300 of 5000\n",
            "Completed 400 of 5000\n",
            "Completed 500 of 5000\n",
            "Completed 600 of 5000\n",
            "Completed 700 of 5000\n",
            "Completed 800 of 5000\n",
            "Completed 900 of 5000\n",
            "Completed 1000 of 5000\n",
            "Completed 1100 of 5000\n",
            "Completed 1200 of 5000\n",
            "Completed 1300 of 5000\n",
            "Completed 1400 of 5000\n",
            "Completed 1500 of 5000\n",
            "Completed 1600 of 5000\n",
            "Completed 1700 of 5000\n",
            "Completed 1800 of 5000\n",
            "Completed 1900 of 5000\n",
            "Completed 2000 of 5000\n",
            "Completed 2100 of 5000\n",
            "Completed 2200 of 5000\n",
            "Completed 2300 of 5000\n",
            "Completed 2400 of 5000\n",
            "Completed 2500 of 5000\n",
            "Completed 2600 of 5000\n",
            "Completed 2700 of 5000\n",
            "Completed 2800 of 5000\n",
            "Completed 2900 of 5000\n",
            "Completed 3000 of 5000\n",
            "Completed 3100 of 5000\n",
            "Completed 3200 of 5000\n",
            "Completed 3300 of 5000\n",
            "Completed 3400 of 5000\n",
            "Completed 3500 of 5000\n",
            "Completed 3600 of 5000\n",
            "Completed 3700 of 5000\n",
            "Completed 3800 of 5000\n",
            "Completed 3900 of 5000\n",
            "Completed 4000 of 5000\n",
            "Completed 4100 of 5000\n",
            "Completed 4200 of 5000\n",
            "Completed 4300 of 5000\n",
            "Completed 4400 of 5000\n",
            "Completed 4500 of 5000\n",
            "Completed 4600 of 5000\n",
            "Completed 4700 of 5000\n",
            "Completed 4800 of 5000\n",
            "Completed 4900 of 5000\n",
            "step 5000/5000: dist 9.3269117e-02 | loss 9.3269117e-02\n",
            "Elapsed time: 10m 05s\n",
            "Creating output directory...\n",
            "Saving projection results...\n",
            "torch.Size([16, 512])\n",
            "tensor([[ 0.1007,  0.2078,  0.3057,  ...,  0.2722,  0.2404,  0.2357],\n",
            "        [ 6.7888,  1.3645,  4.4612,  ...,  2.9375,  0.3774,  9.4554],\n",
            "        [10.5884,  2.0706,  2.8283,  ...,  1.6175,  8.3474,  3.4625],\n",
            "        ...,\n",
            "        [ 0.2007,  3.8584,  5.6427,  ...,  1.7758, 11.7384, -0.4698],\n",
            "        [-0.9779,  0.8539, -0.4201,  ...,  1.9575, -1.4857, -1.8007],\n",
            "        [ 0.4737, -4.2289,  0.8074,  ..., -2.1968,  2.5101,  0.6427]],\n",
            "       device='cuda:0')\n",
            "Saving optimization progress video \"projection_source_vectors/00009-projection-wplus-wavgstart-sgan2/proj_wplus_wavg.mp4\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection Generation"
      ],
      "metadata": {
        "id": "5I7fzlAR7qfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get set of most recent training checkpoints\n",
        "most_recent_training_result = os.listdir(training_outdir)[-1]\n",
        "print(most_recent_training_result)\n",
        "\n",
        "path_to_most_recent_training_result = f\"{training_outdir}/{most_recent_training_result}\"\n",
        "training_checkpoints = [f\"{path_to_most_recent_training_result}/{f}\" for f in os.listdir(path_to_most_recent_training_result) if f.endswith('.pkl')]\n",
        "print(training_checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3qW_Mgh_X1L",
        "outputId": "1dd0c9fc-a4c3-4c86-efb5-48bfd6914a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./results/butterfly\n",
            "00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256\n",
            "['./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000000.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000001.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000002.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000003.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000004.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000005.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000006.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000007.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000008.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000009.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000010.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000011.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000012.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000013.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000014.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000015.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000016.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000017.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000018.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000019.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000020.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000021.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000022.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000023.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000024.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000025.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000026.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000027.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000028.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000029.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000030.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000031.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000032.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000033.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000034.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000035.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000036.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000037.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000038.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000039.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000040.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000042.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000043.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000044.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000045.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000046.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000047.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000048.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000049.pkl', './results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000050.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# projected_w_path = f\"{projection_source_vectors_outdir}/00001-projection-w-wavgstart-sgan2/projected_wavg_final.npy\"\n",
        "# result_name=\"test_result\"\n",
        "\n",
        "ffhqu256_pkl = gen_utils.resume_specs[\"stylegan3-r\"][\"ffhqu256\"];\n",
        "# projection_network_pkl = gen_utils.resume_specs[\"stylegan3-r\"][\"ffhqu256\"];\n",
        "network_name=\"stylegan3-r_ffhqu256\"\n",
        "\n",
        "# projection_network_pkl = \n",
        "\n",
        "projection_outdir=f\"{results_outdir}/projections\"\n",
        "# os.listdir(training_outdir)[-2]\n",
        "\n",
        "projection_version_count = len(os.listdir(projection_outdir)) + 1\n",
        "projection_version_count_padded = f'{projection_version_count:04}'\n",
        "projection_outdir_version = f\"{projection_outdir}/{projection_version_count_padded}_{network_name}\"\n",
        "\n",
        "\n",
        "\n",
        "print(projection_outdir_version)\n",
        "\n",
        "if not os.path.isdir(projection_outdir_version):\n",
        "  !mkdir -p $projection_outdir_version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO6SoYj_6BN6",
        "outputId": "ba5c3ec0-7afa-41d7-9532-a3beb53481d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./results/butterfly/projections/0008_stylegan3-r_ffhqu256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate image from projection\n",
        "projected_w = np.load(projected_w_path)\n",
        "print(projected_w.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "NQJZ0q6OO1-8",
        "outputId": "e84f84c6-efce-4156-e32e-a7c416f2aac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e039bc75609f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate image from projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprojected_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_w_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'projected_w_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate N images across network blend\n",
        "import torch\n",
        "import dnnlib\n",
        "from dnnlib.util import format_time\n",
        "import legacy\n",
        "import PIL.Image\n",
        "\n",
        "from torch_utils import gen_utils\n",
        "\n",
        "\n",
        "# projection_network_pkl = gen_utils.resume_specs[\"stylegan3-r\"][\"ffhqu256\"]\n",
        "\n",
        "\n",
        "def gen_img_from_network(network_pkl_path):\n",
        "  network_pkl_name = network_pkl_path.split('/')[-1]\n",
        "  print('Loading networks from \"%s\"...' % network_pkl_path)\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl_path) as fp:\n",
        "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device)\n",
        "\n",
        "  projected_w_tensor = torch.tensor(projected_w).to(device)\n",
        "  synth_image = gen_utils.w_to_img(G, dlatents=projected_w_tensor, noise_mode='const')[0]\n",
        "  PIL.Image.fromarray(synth_image, 'RGB').save(f'{projection_outdir}/{network_pkl_name}.jpg')\n",
        "\n",
        "for training_checkpoint in training_checkpoints:\n",
        "  gen_img_from_network(training_checkpoint)"
      ],
      "metadata": {
        "id": "YxiBj8ZuO59O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging Image Generation\n",
        "\n",
        "My images dont look similar to the seeds so I'm investigating if there is a discrepency in my generation pipeline"
      ],
      "metadata": {
        "id": "js22OWCVqeNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_utils import gen_utils\n",
        "\n",
        "generated_images_outdir = f\"{results_outdir}/gen_images\"\n",
        "generated_images_network = gen_utils.resume_specs[\"stylegan3-r\"][\"ffhqu256\"];\n",
        "network_name = \"stylegan3-r_ffhqu256\"\n",
        "\n",
        "# generated_images_network = training_checkpoints[13];\n",
        "# network_name = f\"{network_key}_{generated_images_network.split('/')[-1]}\""
      ],
      "metadata": {
        "id": "F3F-qswYq6VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images_version_count = len(os.listdir(generated_images_outdir))\n",
        "generated_images_version_count_padded = f'{generated_images_version_count:04}'\n",
        "generated_images_outdir_version = f\"{generated_images_outdir}/{generated_images_version_count_padded}_{network_name}\"\n",
        "print(f\"Outputting to {generated_images_outdir_version}\")\n",
        "\n",
        "!python gen_images.py --outdir=$generated_images_outdir_version --trunc=1 --seeds=0 --save_vectors=True \\\n",
        "        --network=$generated_images_network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUPuf9zIqh4X",
        "outputId": "7b60af66-1694-4af6-f9ad-49be70ad989e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputting to ./results/butterfly/gen_images/0005_stylegan3-r_ffhqu256\n",
            "Loading networks from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\"...\n",
            "Downloading https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl ... done\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_utils import gen_utils\n",
        "\n",
        "def z_to_img(G, latents: torch.Tensor, label: torch.Tensor, truncation_psi: float, noise_mode: str = 'const') -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Get an image/np.ndarray from a latent Z using G, the label, truncation_psi, and noise_mode. The shape\n",
        "    of the output image/np.ndarray will be [len(latents), G.img_resolution, G.img_resolution, G.img_channels]\n",
        "    \"\"\"\n",
        "    dlatents = gen_utils.z_to_dlatent(G=G, latents=latents, label=label, truncation_psi=truncation_psi)\n",
        "    dlatents = G.mapping.w_avg + (G.mapping.w_avg - dlatents) * truncation_psi\n",
        "    img = gen_utils.w_to_img(G=G, dlatents=dlatents, noise_mode=noise_mode)  # Let's not redo code\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "WnzBBoUG7Am-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate image from Z\n",
        "from torch_utils import gen_utils\n",
        "\n",
        "z_path = \"/content/drive/MyDrive/stylegan3-fun-blend/results/butterfly/gen_images/0005_stylegan3-r_ffhqu256/0000_z.npy\"\n",
        "\n",
        "def gen_img_from_network_and_z(network_pkl_path, z_file_path):\n",
        "  file_output_dir = f'{generated_images_outdir_version}/z_to_img2.jpg'\n",
        "\n",
        "  network_pkl_name = network_pkl_path.split('/')[-1]\n",
        "  print('Loading networks from \"%s\"...' % network_pkl_path)\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl_path) as fp:\n",
        "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device)\n",
        "\n",
        "  z_np = np.load(z_file_path)[0]\n",
        "  z = torch.tensor(z_np).to(device)\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "\n",
        "  # These produce DIFFERENT results ?!?!?\n",
        "  # synth_image = z_to_img(G, latents=z, label=label, truncation_psi=1)[0]\n",
        "  # PIL.Image.fromarray(synth_image, 'RGB').save(file_output_dir)\n",
        "\n",
        "  img = G(z, label, truncation_psi=1, noise_mode=\"const\")\n",
        "  img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
        "  PIL.Image.fromarray(img[0], 'RGB').save(file_output_dir)\n",
        "\n",
        "\n",
        "  print(f\"Outputted file to {file_output_dir}\")\n",
        "gen_img_from_network_and_z(generated_images_network, z_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "eWnM5q36zNYl",
        "outputId": "5123020f-8555-4a85-b2c5-00562cb915fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\"...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c237099cb2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Outputted file to {file_output_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mgen_img_from_network_and_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-c237099cb2aa>\u001b[0m in \u001b[0;36mgen_img_from_network_and_z\u001b[0;34m(network_pkl_path, z_file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_pkl_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_network_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G_ema'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mz_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate from W\n",
        "def gen_img_from_network_and_w(network_pkl_path, w_file_path):\n",
        "  generated_image_count = len(os.listdir(projection_outdir_version))\n",
        "  generated_image_count_padded = f\"{generated_image_count:04}\"\n",
        "  file_output_dir = f'{projection_outdir_version}/{generated_image_count_padded}_w_to_img.jpg'\n",
        "  network_pkl_name = network_pkl_path.split('/')[-1]\n",
        "  print('Loading networks from \"%s\"...' % network_pkl_path)\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl_path) as fp:\n",
        "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device)\n",
        "\n",
        "  w_np = np.load(projected_w_path)[0]\n",
        "  print(w_np.shape)\n",
        "  w = torch.tensor(w_np).to(device)\n",
        "  # print(w)\n",
        "\n",
        "  # img = G.synthesis(w.unsqueeze(0), noise_mode=\"const\")\n",
        "  # img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  # img = PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{file_output_dir}')\n",
        "  synth_image = gen_utils.w_to_img(G, dlatents=w, noise_mode='const')[0]\n",
        "  PIL.Image.fromarray(synth_image, 'RGB').save(f'{file_output_dir}')\n",
        "  print(f\"Outputted image to {file_output_dir}\")\n"
      ],
      "metadata": {
        "id": "505GnnricGYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# projected_w_path = \"/content/drive/MyDrive/stylegan3-fun-blend/projection_source_vectors/00004-projection-wplus-wavgstart-sgan2/projected_wplus_wavg_final.npy\"\n",
        "projected_w_path = \"/content/drive/MyDrive/stylegan3-fun-blend/projection_source_vectors/00008-projection-wplus-wavgstart-sgan2/projected_wplus_wavg_final.npy\"\n",
        "# gen_img_from_network_and_w(training_checkpoints[13], projected_w_path)\n",
        "# gen_img_from_network_and_w(generated_images_network, projected_w_path)"
      ],
      "metadata": {
        "id": "MF5A16RwdGOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for training_checkpoint in training_checkpoints:\n",
        "  gen_img_from_network_and_w(training_checkpoint, projected_w_path)"
      ],
      "metadata": {
        "id": "5QAzE8sFE2pI",
        "outputId": "fea63325-c6cc-4d91-d589-84a6e5840c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000000.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0000_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000001.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0001_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000002.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0002_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000003.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0003_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000004.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0004_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000005.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0005_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000006.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0006_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000007.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0007_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000008.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0008_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000009.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0009_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000010.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0010_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000011.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0011_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000012.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0012_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000013.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0013_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000014.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0014_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000015.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0015_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000016.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0016_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000017.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0017_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000018.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0018_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000019.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0019_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000020.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0020_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000021.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0021_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000022.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0022_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000023.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0023_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000024.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0024_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000025.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0025_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000026.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0026_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000027.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0027_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000028.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0028_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000029.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0029_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000030.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0030_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000031.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0031_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000032.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0032_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000033.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0033_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000034.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0034_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000035.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0035_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000036.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0036_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000037.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0037_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000038.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0038_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000039.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0039_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000040.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0040_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000042.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0041_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000043.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0042_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000044.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0043_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000045.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0044_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000046.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0045_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000047.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0046_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000048.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0047_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000049.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0048_w_to_img.jpg\n",
            "Loading networks from \"./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000050.pkl\"...\n",
            "(16, 512)\n",
            "Outputted image to ./results/butterfly/projections/0006_stylegan3-r_ffhqu256/0049_w_to_img.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selection"
      ],
      "metadata": {
        "id": "LHsHlJHI7viM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refinement"
      ],
      "metadata": {
        "id": "WilXQgAn7_-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blending Script"
      ],
      "metadata": {
        "id": "SdFOHCREdv8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blend_to_pkl = training_checkpoints[-1]\n",
        "\n",
        "!python stylegan_blending.py --network1 $ffhqu256_pkl \\\n",
        "        --network2 $blend_to_pkl \\\n",
        "            --outdir butterflys/blend --dim 256"
      ],
      "metadata": {
        "id": "XpgE7jUHdxk8",
        "outputId": "037efe24-e9d3-4377-e629-48676770dc66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl and ./results/butterfly/training/00008-stylegan3-r-butterflys_256_2-256x256-gpus1-batch32-gamma6.6-resume_ffhqu256/network-snapshot-000050.pkl ...\n",
            "Generator(\n",
            "  (synthesis): SynthesisNetwork(\n",
            "    w_dim=512, num_ws=16,\n",
            "    img_resolution=256, img_channels=3,\n",
            "    num_layers=14, num_critical=2,\n",
            "    margin_size=10, num_fp16_res=4\n",
            "    (input): SynthesisInput(\n",
            "      w_dim=512, channels=1024, size=[36, 36],\n",
            "      sampling_rate=16, bandwidth=2\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=4, activation=linear)\n",
            "    )\n",
            "    (L0_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2, out_cutoff=2,\n",
            "      in_half_width=6, out_half_width=6,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L1_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2, out_cutoff=2.82843,\n",
            "      in_half_width=6, out_half_width=5.17157,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L2_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2.82843, out_cutoff=4,\n",
            "      in_half_width=5.17157, out_half_width=4,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L3_52_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=16, out_sampling_rate=32,\n",
            "      in_cutoff=4, out_cutoff=5.65685,\n",
            "      in_half_width=4, out_half_width=10.3431,\n",
            "      in_size=[36, 36], out_size=[52, 52],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L4_52_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=32, out_sampling_rate=32,\n",
            "      in_cutoff=5.65685, out_cutoff=8,\n",
            "      in_half_width=10.3431, out_half_width=8,\n",
            "      in_size=[52, 52], out_size=[52, 52],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L5_84_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=32, out_sampling_rate=64,\n",
            "      in_cutoff=8, out_cutoff=11.3137,\n",
            "      in_half_width=8, out_half_width=20.6863,\n",
            "      in_size=[52, 52], out_size=[84, 84],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L6_84_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=64, out_sampling_rate=64,\n",
            "      in_cutoff=11.3137, out_cutoff=16,\n",
            "      in_half_width=20.6863, out_half_width=16,\n",
            "      in_size=[84, 84], out_size=[84, 84],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L7_148_724): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=64, out_sampling_rate=128,\n",
            "      in_cutoff=16, out_cutoff=22.6274,\n",
            "      in_half_width=16, out_half_width=41.3726,\n",
            "      in_size=[84, 84], out_size=[148, 148],\n",
            "      in_channels=1024, out_channels=724\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L8_148_512): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=128,\n",
            "      in_cutoff=22.6274, out_cutoff=32,\n",
            "      in_half_width=41.3726, out_half_width=32,\n",
            "      in_size=[148, 148], out_size=[148, 148],\n",
            "      in_channels=724, out_channels=512\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=724, activation=linear)\n",
            "    )\n",
            "    (L9_148_362): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=128,\n",
            "      in_cutoff=32, out_cutoff=45.2548,\n",
            "      in_half_width=32, out_half_width=18.7452,\n",
            "      in_size=[148, 148], out_size=[148, 148],\n",
            "      in_channels=512, out_channels=362\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
            "    )\n",
            "    (L10_276_256): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=256,\n",
            "      in_cutoff=45.2548, out_cutoff=64,\n",
            "      in_half_width=18.7452, out_half_width=64,\n",
            "      in_size=[148, 148], out_size=[276, 276],\n",
            "      in_channels=362, out_channels=256\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=362, activation=linear)\n",
            "    )\n",
            "    (L11_276_181): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=64, out_cutoff=90.5097,\n",
            "      in_half_width=64, out_half_width=37.4903,\n",
            "      in_size=[276, 276], out_size=[276, 276],\n",
            "      in_channels=256, out_channels=181\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
            "    )\n",
            "    (L12_276_128): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=90.5097, out_cutoff=128,\n",
            "      in_half_width=37.4903, out_half_width=29.5865,\n",
            "      in_size=[276, 276], out_size=[276, 276],\n",
            "      in_channels=181, out_channels=128\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=181, activation=linear)\n",
            "    )\n",
            "    (L13_256_128): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=128, out_cutoff=128,\n",
            "      in_half_width=29.5865, out_half_width=29.5865,\n",
            "      in_size=[276, 276], out_size=[256, 256],\n",
            "      in_channels=128, out_channels=128\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
            "    )\n",
            "    (L14_256_3): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=True,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=128, out_cutoff=128,\n",
            "      in_half_width=29.5865, out_half_width=29.5865,\n",
            "      in_size=[256, 256], out_size=[256, 256],\n",
            "      in_channels=128, out_channels=3\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
            "    )\n",
            "  )\n",
            "  (mapping): MappingNetwork(\n",
            "    z_dim=512, c_dim=0, w_dim=512, num_ws=16\n",
            "    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
            "    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
            "  )\n",
            ")\n",
            "7\n",
            "[4, 8, 16, 32, 64, 128, 256]\n",
            "['synthesis.input.weight', 'synthesis.input.affine.weight', 'synthesis.input.affine.bias', 'synthesis.L0_36_1024.weight', 'synthesis.L0_36_1024.bias', 'synthesis.L0_36_1024.affine.weight', 'synthesis.L0_36_1024.affine.bias', 'synthesis.L1_36_1024.weight', 'synthesis.L1_36_1024.bias', 'synthesis.L1_36_1024.affine.weight', 'synthesis.L1_36_1024.affine.bias', 'synthesis.L2_36_1024.weight', 'synthesis.L2_36_1024.bias', 'synthesis.L2_36_1024.affine.weight', 'synthesis.L2_36_1024.affine.bias', 'synthesis.L3_52_1024.weight', 'synthesis.L3_52_1024.bias', 'synthesis.L3_52_1024.affine.weight', 'synthesis.L3_52_1024.affine.bias', 'synthesis.L4_52_1024.weight', 'synthesis.L4_52_1024.bias', 'synthesis.L4_52_1024.affine.weight', 'synthesis.L4_52_1024.affine.bias', 'synthesis.L5_84_1024.weight', 'synthesis.L5_84_1024.bias', 'synthesis.L5_84_1024.affine.weight', 'synthesis.L5_84_1024.affine.bias', 'synthesis.L6_84_1024.weight', 'synthesis.L6_84_1024.bias', 'synthesis.L6_84_1024.affine.weight', 'synthesis.L6_84_1024.affine.bias', 'synthesis.L7_148_724.weight', 'synthesis.L7_148_724.bias', 'synthesis.L7_148_724.affine.weight', 'synthesis.L7_148_724.affine.bias', 'synthesis.L8_148_512.weight', 'synthesis.L8_148_512.bias', 'synthesis.L8_148_512.affine.weight', 'synthesis.L8_148_512.affine.bias', 'synthesis.L9_148_362.weight', 'synthesis.L9_148_362.bias', 'synthesis.L9_148_362.affine.weight', 'synthesis.L9_148_362.affine.bias', 'synthesis.L10_276_256.weight', 'synthesis.L10_276_256.bias', 'synthesis.L10_276_256.affine.weight', 'synthesis.L10_276_256.affine.bias', 'synthesis.L11_276_181.weight', 'synthesis.L11_276_181.bias', 'synthesis.L11_276_181.affine.weight', 'synthesis.L11_276_181.affine.bias', 'synthesis.L12_276_128.weight', 'synthesis.L12_276_128.bias', 'synthesis.L12_276_128.affine.weight', 'synthesis.L12_276_128.affine.bias', 'synthesis.L13_256_128.weight', 'synthesis.L13_256_128.bias', 'synthesis.L13_256_128.affine.weight', 'synthesis.L13_256_128.affine.bias', 'synthesis.L14_256_3.weight', 'synthesis.L14_256_3.bias', 'synthesis.L14_256_3.affine.weight', 'synthesis.L14_256_3.affine.bias', 'mapping.fc0.weight', 'mapping.fc0.bias', 'mapping.fc1.weight', 'mapping.fc1.bias']\n",
            "Generator(\n",
            "  (synthesis): SynthesisNetwork(\n",
            "    w_dim=512, num_ws=16,\n",
            "    img_resolution=256, img_channels=3,\n",
            "    num_layers=14, num_critical=2,\n",
            "    margin_size=10, num_fp16_res=4\n",
            "    (input): SynthesisInput(\n",
            "      w_dim=512, channels=1024, size=[36, 36],\n",
            "      sampling_rate=16, bandwidth=2\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=4, activation=linear)\n",
            "    )\n",
            "    (L0_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2, out_cutoff=2,\n",
            "      in_half_width=6, out_half_width=6,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L1_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2, out_cutoff=2.82843,\n",
            "      in_half_width=6, out_half_width=5.17157,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L2_36_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=False,\n",
            "      in_sampling_rate=16, out_sampling_rate=16,\n",
            "      in_cutoff=2.82843, out_cutoff=4,\n",
            "      in_half_width=5.17157, out_half_width=4,\n",
            "      in_size=[36, 36], out_size=[36, 36],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L3_52_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=16, out_sampling_rate=32,\n",
            "      in_cutoff=4, out_cutoff=5.65685,\n",
            "      in_half_width=4, out_half_width=10.3431,\n",
            "      in_size=[36, 36], out_size=[52, 52],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L4_52_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=32, out_sampling_rate=32,\n",
            "      in_cutoff=5.65685, out_cutoff=8,\n",
            "      in_half_width=10.3431, out_half_width=8,\n",
            "      in_size=[52, 52], out_size=[52, 52],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L5_84_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=32, out_sampling_rate=64,\n",
            "      in_cutoff=8, out_cutoff=11.3137,\n",
            "      in_half_width=8, out_half_width=20.6863,\n",
            "      in_size=[52, 52], out_size=[84, 84],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L6_84_1024): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=64, out_sampling_rate=64,\n",
            "      in_cutoff=11.3137, out_cutoff=16,\n",
            "      in_half_width=20.6863, out_half_width=16,\n",
            "      in_size=[84, 84], out_size=[84, 84],\n",
            "      in_channels=1024, out_channels=1024\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L7_148_724): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=64, out_sampling_rate=128,\n",
            "      in_cutoff=16, out_cutoff=22.6274,\n",
            "      in_half_width=16, out_half_width=41.3726,\n",
            "      in_size=[84, 84], out_size=[148, 148],\n",
            "      in_channels=1024, out_channels=724\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=1024, activation=linear)\n",
            "    )\n",
            "    (L8_148_512): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=128,\n",
            "      in_cutoff=22.6274, out_cutoff=32,\n",
            "      in_half_width=41.3726, out_half_width=32,\n",
            "      in_size=[148, 148], out_size=[148, 148],\n",
            "      in_channels=724, out_channels=512\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=724, activation=linear)\n",
            "    )\n",
            "    (L9_148_362): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=128,\n",
            "      in_cutoff=32, out_cutoff=45.2548,\n",
            "      in_half_width=32, out_half_width=18.7452,\n",
            "      in_size=[148, 148], out_size=[148, 148],\n",
            "      in_channels=512, out_channels=362\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
            "    )\n",
            "    (L10_276_256): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=128, out_sampling_rate=256,\n",
            "      in_cutoff=45.2548, out_cutoff=64,\n",
            "      in_half_width=18.7452, out_half_width=64,\n",
            "      in_size=[148, 148], out_size=[276, 276],\n",
            "      in_channels=362, out_channels=256\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=362, activation=linear)\n",
            "    )\n",
            "    (L11_276_181): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=False, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=64, out_cutoff=90.5097,\n",
            "      in_half_width=64, out_half_width=37.4903,\n",
            "      in_size=[276, 276], out_size=[276, 276],\n",
            "      in_channels=256, out_channels=181\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
            "    )\n",
            "    (L12_276_128): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=90.5097, out_cutoff=128,\n",
            "      in_half_width=37.4903, out_half_width=29.5865,\n",
            "      in_size=[276, 276], out_size=[276, 276],\n",
            "      in_channels=181, out_channels=128\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=181, activation=linear)\n",
            "    )\n",
            "    (L13_256_128): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=False,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=128, out_cutoff=128,\n",
            "      in_half_width=29.5865, out_half_width=29.5865,\n",
            "      in_size=[276, 276], out_size=[256, 256],\n",
            "      in_channels=128, out_channels=128\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
            "    )\n",
            "    (L14_256_3): SynthesisLayer(\n",
            "      w_dim=512, is_torgb=True,\n",
            "      is_critically_sampled=True, use_fp16=True,\n",
            "      in_sampling_rate=256, out_sampling_rate=256,\n",
            "      in_cutoff=128, out_cutoff=128,\n",
            "      in_half_width=29.5865, out_half_width=29.5865,\n",
            "      in_size=[256, 256], out_size=[256, 256],\n",
            "      in_channels=128, out_channels=3\n",
            "      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
            "    )\n",
            "  )\n",
            "  (mapping): MappingNetwork(\n",
            "    z_dim=512, c_dim=0, w_dim=512, num_ws=16\n",
            "    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
            "    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
            "  )\n",
            ")\n",
            "7\n",
            "[4, 8, 16, 32, 64, 128, 256]\n",
            "['synthesis.input.weight', 'synthesis.input.affine.weight', 'synthesis.input.affine.bias', 'synthesis.L0_36_1024.weight', 'synthesis.L0_36_1024.bias', 'synthesis.L0_36_1024.affine.weight', 'synthesis.L0_36_1024.affine.bias', 'synthesis.L1_36_1024.weight', 'synthesis.L1_36_1024.bias', 'synthesis.L1_36_1024.affine.weight', 'synthesis.L1_36_1024.affine.bias', 'synthesis.L2_36_1024.weight', 'synthesis.L2_36_1024.bias', 'synthesis.L2_36_1024.affine.weight', 'synthesis.L2_36_1024.affine.bias', 'synthesis.L3_52_1024.weight', 'synthesis.L3_52_1024.bias', 'synthesis.L3_52_1024.affine.weight', 'synthesis.L3_52_1024.affine.bias', 'synthesis.L4_52_1024.weight', 'synthesis.L4_52_1024.bias', 'synthesis.L4_52_1024.affine.weight', 'synthesis.L4_52_1024.affine.bias', 'synthesis.L5_84_1024.weight', 'synthesis.L5_84_1024.bias', 'synthesis.L5_84_1024.affine.weight', 'synthesis.L5_84_1024.affine.bias', 'synthesis.L6_84_1024.weight', 'synthesis.L6_84_1024.bias', 'synthesis.L6_84_1024.affine.weight', 'synthesis.L6_84_1024.affine.bias', 'synthesis.L7_148_724.weight', 'synthesis.L7_148_724.bias', 'synthesis.L7_148_724.affine.weight', 'synthesis.L7_148_724.affine.bias', 'synthesis.L8_148_512.weight', 'synthesis.L8_148_512.bias', 'synthesis.L8_148_512.affine.weight', 'synthesis.L8_148_512.affine.bias', 'synthesis.L9_148_362.weight', 'synthesis.L9_148_362.bias', 'synthesis.L9_148_362.affine.weight', 'synthesis.L9_148_362.affine.bias', 'synthesis.L10_276_256.weight', 'synthesis.L10_276_256.bias', 'synthesis.L10_276_256.affine.weight', 'synthesis.L10_276_256.affine.bias', 'synthesis.L11_276_181.weight', 'synthesis.L11_276_181.bias', 'synthesis.L11_276_181.affine.weight', 'synthesis.L11_276_181.affine.bias', 'synthesis.L12_276_128.weight', 'synthesis.L12_276_128.bias', 'synthesis.L12_276_128.affine.weight', 'synthesis.L12_276_128.affine.bias', 'synthesis.L13_256_128.weight', 'synthesis.L13_256_128.bias', 'synthesis.L13_256_128.affine.weight', 'synthesis.L13_256_128.affine.bias', 'synthesis.L14_256_3.weight', 'synthesis.L14_256_3.bias', 'synthesis.L14_256_3.affine.weight', 'synthesis.L14_256_3.affine.bias', 'mapping.fc0.weight', 'mapping.fc0.bias', 'mapping.fc1.weight', 'mapping.fc1.bias']\n",
            "[]\n",
            "[]\n",
            "Traceback (most recent call last):\n",
            "  File \"stylegan_blending.py\", line 347, in <module>\n",
            "    generate_images()  # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/decorators.py\", line 21, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"stylegan_blending.py\", line 340, in generate_images\n",
            "    projected_w=projected_w,\n",
            "  File \"stylegan_blending.py\", line 161, in run_blend_images\n",
            "    verbose=verbose,\n",
            "  File \"stylegan_blending.py\", line 68, in get_blended_model\n",
            "    mid_point_idx = short_names.index((resolution, level))\n",
            "ValueError: ('b4', 0) is not in list\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a8b6964c4b11971ada34c31ca3858cac76f4677604ed4191f9e9f62d73997475"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('pytorch2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Copy of blend.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}